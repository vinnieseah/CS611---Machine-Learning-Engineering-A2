{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50484d2-bfa4-40b6-82cd-e8bf86187cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c91bb1-bcf0-4195-90f3-dc88806ebf8c",
   "metadata": {},
   "source": [
    "## set up pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fb3bc6-4166-4893-88e1-0d3140df5a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The operation couldnâ€™t be completed. Unable to locate a Java Runtime.\n",
      "Please visit http://www.java.com for information on installing Java.\n",
      "\n",
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/pyspark/bin/spark-class: line 97: CMD: bad array subscript\n",
      "head: illegal line count -- -1\n"
     ]
    },
    {
     "ename": "PySparkRuntimeError",
     "evalue": "[JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPySparkRuntimeError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize SparkSession\u001b[39;00m\n\u001b[32m      2\u001b[39m spark = \u001b[43mpyspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdev\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocal[*]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Set log level to ERROR to hide warnings\u001b[39;00m\n\u001b[32m      8\u001b[39m spark.sparkContext.setLogLevel(\u001b[33m\"\u001b[39m\u001b[33mERROR\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pyspark/sql/session.py:556\u001b[39m, in \u001b[36mSparkSession.Builder.getOrCreate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    554\u001b[39m     sparkConf.set(key, value)\n\u001b[32m    555\u001b[39m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m sc = \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[32m    559\u001b[39m session = SparkSession(sc, options=\u001b[38;5;28mself\u001b[39m._options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pyspark/core/context.py:523\u001b[39m, in \u001b[36mSparkContext.getOrCreate\u001b[39m\u001b[34m(cls, conf)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext._active_spark_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pyspark/core/context.py:205\u001b[39m, in \u001b[36mSparkContext.__init__\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway.gateway_parameters.auth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is not allowed as it is a security risk.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28mself\u001b[39m._do_init(\n\u001b[32m    208\u001b[39m         master,\n\u001b[32m    209\u001b[39m         appName,\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m         memory_profiler_cls,\n\u001b[32m    220\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pyspark/core/context.py:444\u001b[39m, in \u001b[36mSparkContext._ensure_initialized\u001b[39m\u001b[34m(cls, instance, gateway, conf)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    443\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext._gateway:\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m         SparkContext._gateway = gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m         SparkContext._jvm = SparkContext._gateway.jvm\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pyspark/java_gateway.py:111\u001b[39m, in \u001b[36mlaunch_gateway\u001b[39m\u001b[34m(conf, popen_kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m     time.sleep(\u001b[32m0.1\u001b[39m)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(conn_info_file):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[32m    112\u001b[39m         errorClass=\u001b[33m\"\u001b[39m\u001b[33mJAVA_GATEWAY_EXITED\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    113\u001b[39m         messageParameters={},\n\u001b[32m    114\u001b[39m     )\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[32m    117\u001b[39m     gateway_port = read_int(info)\n",
      "\u001b[31mPySparkRuntimeError\u001b[39m: [JAVA_GATEWAY_EXITED] Java gateway process exited before sending its port number."
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30206071-5f00-4c3b-be13-55c54db8e336",
   "metadata": {},
   "source": [
    "## set up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3a464-fe45-477b-8815-cebe102228f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up config\n",
    "model_train_date_str = \"2024-09-01\"\n",
    "train_test_period_months = 12\n",
    "oot_period_months = 2\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "config = {}\n",
    "config[\"model_train_date_str\"] = model_train_date_str\n",
    "config[\"train_test_period_months\"] = train_test_period_months\n",
    "config[\"oot_period_months\"] =  oot_period_months\n",
    "config[\"model_train_date\"] =  datetime.strptime(model_train_date_str, \"%Y-%m-%d\")\n",
    "config[\"oot_end_date\"] =  config['model_train_date'] - timedelta(days = 1)\n",
    "config[\"oot_start_date\"] =  config['model_train_date'] - relativedelta(months = oot_period_months)\n",
    "config[\"train_test_end_date\"] =  config[\"oot_start_date\"] - timedelta(days = 1)\n",
    "config[\"train_test_start_date\"] =  config[\"oot_start_date\"] - relativedelta(months = train_test_period_months)\n",
    "config[\"train_test_ratio\"] = train_test_ratio \n",
    "\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eeb8a3-7737-4556-a85c-e844b47f6454",
   "metadata": {},
   "source": [
    "## get label store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc72e2-90ed-46da-8c6e-599573d54049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to label store\n",
    "folder_path = \"datamart/gold/label_store/\"\n",
    "files_list = [folder_path+os.path.basename(f) for f in glob.glob(os.path.join(folder_path, '*'))]\n",
    "label_store_sdf = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "print(\"row_count:\",label_store_sdf.count())\n",
    "\n",
    "label_store_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20833e-9653-4c4c-9ce0-0023cca719b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract label store\n",
    "labels_sdf = label_store_sdf.filter((col(\"snapshot_date\") >= config[\"train_test_start_date\"]) & (col(\"snapshot_date\") <= config[\"oot_end_date\"]))\n",
    "\n",
    "print(\"extracted labels_sdf\", labels_sdf.count(), config[\"train_test_start_date\"], config[\"oot_end_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfee45c-3612-4c9b-9f8e-fbbf3caa3bc5",
   "metadata": {},
   "source": [
    "## get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993669e4-49b4-4329-a842-714023a3fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_location = \"data/feature_clickstream.csv\"\n",
    "\n",
    "# Load CSV into DataFrame - connect to feature store\n",
    "features_store_sdf = spark.read.csv(feature_location, header=True, inferSchema=True)\n",
    "print(\"row_count:\",features_store_sdf.count())\n",
    "\n",
    "features_store_sdf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d8e7e-f374-42b6-8617-64fffc98b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract label store\n",
    "features_sdf = features_store_sdf.filter((col(\"snapshot_date\") >= config[\"train_test_start_date\"]) & (col(\"snapshot_date\") <= config[\"oot_end_date\"]))\n",
    "\n",
    "print(\"extracted features_sdf\", features_sdf.count(), config[\"train_test_start_date\"], config[\"oot_end_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6ada0-efa8-406a-895c-30a86c2d9565",
   "metadata": {},
   "source": [
    "## prepare data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65d173-37c1-4c37-83de-d77de4f60325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for modeling\n",
    "data_pdf = labels_sdf.join(features_sdf, on=[\"Customer_ID\", \"snapshot_date\"], how=\"left\").toPandas()\n",
    "data_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076f5b8-b069-4c90-8300-915ed99671a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train - test - oot\n",
    "oot_pdf = data_pdf[(data_pdf['snapshot_date'] >= config[\"oot_start_date\"].date()) & (data_pdf['snapshot_date'] <= config[\"oot_end_date\"].date())]\n",
    "train_test_pdf = data_pdf[(data_pdf['snapshot_date'] >= config[\"train_test_start_date\"].date()) & (data_pdf['snapshot_date'] <= config[\"train_test_end_date\"].date())]\n",
    "\n",
    "feature_cols = [fe_col for fe_col in data_pdf.columns if fe_col.startswith('fe_')]\n",
    "\n",
    "X_oot = oot_pdf[feature_cols]\n",
    "y_oot = oot_pdf[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_test_pdf[feature_cols], train_test_pdf[\"label\"], \n",
    "    test_size= 1 - config[\"train_test_ratio\"],\n",
    "    random_state=88,     # Ensures reproducibility\n",
    "    shuffle=True,        # Shuffle the data before splitting\n",
    "    stratify=train_test_pdf[\"label\"]           # Stratify based on the label column\n",
    ")\n",
    "\n",
    "\n",
    "print('X_train', X_train.shape[0])\n",
    "print('X_test', X_test.shape[0])\n",
    "print('X_oot', X_oot.shape[0])\n",
    "print('y_train', y_train.shape[0], round(y_train.mean(),2))\n",
    "print('y_test', y_test.shape[0], round(y_test.mean(),2))\n",
    "print('y_oot', y_oot.shape[0], round(y_oot.mean(),2))\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14784ef3-512e-475b-8c56-e1238d305814",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572337a5-8d35-4409-80c0-22fda27810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up standard scalar preprocessing\n",
    "scaler = StandardScaler()\n",
    "\n",
    "transformer_stdscaler = scaler.fit(X_train) # Q which should we use? train? test? oot? all?\n",
    "\n",
    "# transform data\n",
    "X_train_processed = transformer_stdscaler.transform(X_train)\n",
    "X_test_processed = transformer_stdscaler.transform(X_test)\n",
    "X_oot_processed = transformer_stdscaler.transform(X_oot)\n",
    "\n",
    "print('X_train_processed', X_train_processed.shape[0])\n",
    "print('X_test_processed', X_test_processed.shape[0])\n",
    "print('X_oot_processed', X_oot_processed.shape[0])\n",
    "\n",
    "pd.DataFrame(X_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90383aa5-78a6-46dd-aade-a1244adeafd0",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9cb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(eval_metric='logloss', random_state=88),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(random_state=88, verbose=-1),\n",
    "    \"CatBoost\": cb.CatBoostClassifier(random_state=88, verbose=False)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 4, 5, 6],\n",
    "        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'gamma': [0, 0.1, 0.2],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'reg_alpha': [0, 0.01, 0.1],\n",
    "        'reg_lambda': [0.01, 0.1, 1]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 4, 5, 6, -1],\n",
    "        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'num_leaves': [31, 63, 127],\n",
    "        'min_child_samples': [5, 10, 20],\n",
    "        'reg_alpha': [0, 0.01, 0.1],\n",
    "        'reg_lambda': [0.01, 0.1, 1]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'iterations': [50, 100, 200],\n",
    "        'depth': [3, 4, 5, 6],\n",
    "        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bylevel': [0.7, 0.8, 0.9, 1.0],\n",
    "        'l2_leaf_reg': [0.1, 1, 3],\n",
    "        'border_count': [32, 64, 128]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning and result collection\n",
    "results = []\n",
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Training {model_name} ===\")\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        scoring=auc_scorer,\n",
    "        n_iter=50,  # Reduced for faster training\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Perform the random search\n",
    "    random_search.fit(X_train_processed, y_train)\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    # Evaluate on all sets\n",
    "    train_pred = best_model.predict_proba(X_train_processed)[:, 1]\n",
    "    test_pred = best_model.predict_proba(X_test_processed)[:, 1]\n",
    "    oot_pred = best_model.predict_proba(X_oot_processed)[:, 1]\n",
    "    \n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc = roc_auc_score(y_test, test_pred)\n",
    "    oot_auc = roc_auc_score(y_oot, oot_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"BestParams\": random_search.best_params_,\n",
    "        \"CV AUC\": random_search.best_score_,\n",
    "        \"Train AUC\": train_auc,\n",
    "        \"Test AUC\": test_auc,\n",
    "        \"OOT AUC\": oot_auc,\n",
    "        \"Train GINI\": round(2*train_auc-1, 3),\n",
    "        \"Test GINI\": round(2*test_auc-1, 3),\n",
    "        \"OOT GINI\": round(2*oot_auc-1, 3),\n",
    "        \"BestModel\": best_model\n",
    "    })\n",
    "    \n",
    "    print(f\"{model_name} - Test AUC: {test_auc:.4f}, OOT AUC: {oot_auc:.4f}\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "print(results_df[['Model', 'Test AUC', 'OOT AUC', 'Test GINI', 'OOT GINI']].to_string(index=False))\n",
    "\n",
    "# Select best model based on OOT AUC\n",
    "best_model_result = max(results, key=lambda x: x['OOT AUC'])\n",
    "best_model = best_model_result['BestModel']\n",
    "best_model_name = best_model_result['Model']\n",
    "\n",
    "print(f\"\\n=== BEST MODEL: {best_model_name} ===\")\n",
    "print(f\"OOT AUC: {best_model_result['OOT AUC']:.4f}\")\n",
    "print(f\"OOT GINI: {best_model_result['OOT GINI']}\")\n",
    "print(f\"Best Parameters: {best_model_result['BestParams']}\")\n",
    "\n",
    "# Set variables for artifact saving\n",
    "train_auc_score = best_model_result['Train AUC']\n",
    "test_auc_score = best_model_result['Test AUC'] \n",
    "oot_auc_score = best_model_result['OOT AUC']\n",
    "random_search = type('obj', (object,), {'best_estimator_': best_model, 'best_params_': best_model_result['BestParams']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846548ca-a1bb-4625-854e-ac39068f3821",
   "metadata": {},
   "source": [
    "## prepare model artefact to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a720c7-df26-41be-935e-06904983c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artefact = {}\n",
    "\n",
    "model_artefact['model'] = best_model\n",
    "model_artefact['model_version'] = \"credit_model_\"+config[\"model_train_date_str\"].replace('-','_')\n",
    "model_artefact['preprocessing_transformers'] = {}\n",
    "model_artefact['preprocessing_transformers']['stdscaler'] = transformer_stdscaler\n",
    "model_artefact['data_dates'] = config\n",
    "model_artefact['data_stats'] = {}\n",
    "model_artefact['data_stats']['X_train'] = X_train.shape[0]\n",
    "model_artefact['data_stats']['X_test'] = X_test.shape[0]\n",
    "model_artefact['data_stats']['X_oot'] = X_oot.shape[0]\n",
    "model_artefact['data_stats']['y_train'] = round(y_train.mean(),2)\n",
    "model_artefact['data_stats']['y_test'] = round(y_test.mean(),2)\n",
    "model_artefact['data_stats']['y_oot'] = round(y_oot.mean(),2)\n",
    "model_artefact['results'] = {}\n",
    "model_artefact['results']['auc_train'] = train_auc_score\n",
    "model_artefact['results']['auc_test'] = test_auc_score\n",
    "model_artefact['results']['auc_oot'] = oot_auc_score\n",
    "model_artefact['results']['gini_train'] = round(2*train_auc_score-1,3)\n",
    "model_artefact['results']['gini_test'] = round(2*test_auc_score-1,3)\n",
    "model_artefact['results']['gini_oot'] = round(2*oot_auc_score-1,3)\n",
    "model_artefact['hp_params'] = random_search.best_params_\n",
    "\n",
    "\n",
    "pprint.pprint(model_artefact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea194e4-669d-43a6-b31f-ef14f0d188aa",
   "metadata": {},
   "source": [
    "## save artefact to model bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54ff1665-3eef-4b13-8c78-3cfe19fd1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model_bank dir\n",
    "model_bank_directory = \"model_bank/\"\n",
    "\n",
    "if not os.path.exists(model_bank_directory):\n",
    "    os.makedirs(model_bank_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebf078-449b-4e6c-81fa-496d901e97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full path to the file\n",
    "file_path = os.path.join(model_bank_directory, model_artefact['model_version'] + '.pkl')\n",
    "\n",
    "# Write the model to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact, file)\n",
    "\n",
    "print(f\"Model saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c91f891-d285-46ef-8901-d19ec702176b",
   "metadata": {},
   "source": [
    "## test load pickle and make model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1da5b-0766-4ac5-b643-115daad8e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the pickle file\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_model_artefact = pickle.load(file)\n",
    "\n",
    "y_pred_proba = loaded_model_artefact['model'].predict_proba(X_oot_processed)[:, 1]\n",
    "oot_auc_score = roc_auc_score(y_oot, y_pred_proba)\n",
    "print(\"OOT AUC score: \", oot_auc_score)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
